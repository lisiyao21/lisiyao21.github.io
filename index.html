---
layout: default
title: Li Siyao
---

<h1> 
	Li Siyao 
</h1>



<table border="0" cellpadding="3" cellspacing="10">
	<tr>
	<td style="vertical-align:top">
		<img padding="0px 20px 15px 0px" src="accessories/siyao_guqin.jpg"  width="150" height="inherit" border="1px" alt="">
	</td>
	<td style="width:400pt" colspan="3">
		Siyao is currently a first-year PhD student in <a href="https://www.mmlab-ntu.com/">MMLab</a> of Nanyang Technological University, Singapore, advised by <a href="https://liuziwei7.github.io/">Ziwei Liu</a> and <a href="https://www.mmlab-ntu.com/person/ccloy/">Chen Change Loy</a>.
        Before that, he was a full-time researcher in SenseTime Research, working closely with Quan Wang, Wenxiu Sun and <a href="http://xpixel.group/2010/01/20/chaodong.html">Chao Dong</a>.
        
        His current interests includes AI techniques for content creation.

	</td>
	</tr>
</table>


<br>

<!-- <hr> -->

<h2>Selected Publications</h2>

<table border="0" cellpadding="3" cellspacing="10">
	<tr>
		<td><a href="projects/animerun/AnimeRun.html"><img style="vertical-align:middle" src="accessories/animerun.png"  width="200" height="inherit" border="1px" alt="" /></a></td>
		<td>
			<b>AnimeRun: 2D Visual Correspondence from Open Source 3D Movies</b>
            <br> <b>Li Siyao</b>, Yuhang Li, Bo Li, Chao Dong, Ziwei Liu, Chen Change Loy<br>
			<em> NeurIPS 2022 (Dataset & Benchmark Track) </em> <br> 
			[<a href="projects/animerun/AnimeRun.html">Project page</a>] [Paper] [Code]
		</td>
	</tr>
	
	<tr>
		<td><a href="https://github.com/lisiyao21/Bailando"><img style="vertical-align:middle" src="accessories/dance_gif3.gif"  width="200" height="inherit" border="1px" alt="" /></a></td>
		<td>
			<b>Bailando: 3D Dance Generation by Actor-Critic GPT with Choreographic Memory</b>
            <br> <b>Li Siyao</b>, Weijiang Yu, Tianpei Gu, Chunze Lin, Quan Wang, Chen Qian, Chen Change Loy, Ziwei Liu<br>
			<em> CVPR 2022 (Oral, ~4%) </em> <br> 
			[Paper] [<a href="https://github.com/lisiyao21/Bailando">Code</a>]
		</td>
	</tr>
	
	
	<tr>
		<td><a href="https://github.com/lisiyao21/AnimeInterp"><img style="vertical-align:middle" src="accessories/avi_gif.gif"  width="200" height="inherit" border="1px" alt="" /></a></td>
		<td>
			<b>Deep Animation Video Interpolation in the Wild</b> <br> 
			<b>Li Siyao*</b>, Shiyu Zhao*, Weijiang Yu, Wenxiu Sun, Dimitris Metaxas, Chen Change Loy, Ziwei Liu<br> 
			<em> CVPR 2021 </em> <br> 
			[Paper] [<a href="https://github.com/lisiyao21/AnimeInterp">Code</a>] [Data]
		</td>
	</tr>
	
    <tr>
		<td><a href="https://github.com/lyh-18/EQVI"><img style="vertical-align:middle" src="accessories/eqvi.png"  width="200" height="inherit" border="1px" alt="" /></a></td>
		<td>
			<b>Enhanced Quadratic Video Interpolation</b> <br> 
			Yihao Liu*, Liangbin Xie*, <b>Li Siyao</b>, Wenxiu Sun, Yu Qiao, Chao Dong<br> 
			<em> ECCV 2020, AIM Workshop (<b>1st place of AIM-VTSR 2020 challenge!</b>) </em> <br> 
			[Paper] [<a href="https://github.com/lyh-18/EQVI">Code</a>] 
		</td>
	</tr>
	
    <tr>
		<td><img style="vertical-align:middle" src="accessories/qvi.png"  width="200" height="inherit" border="1px" alt="" /></a></td>
		<td>
			<b>Quadratic Video Interpolation</b> <br> 
			Xiangyu Xu*, <b>Li Siyao*</b>, Wenxiu Sun, Qian Yin, Ming-Hsuan Yang<br> 
			<em> NeurIPS (Spotlight, ~15%)</em><br> 
            <em><b>1st place of ICCV AIM-VTSR 2019 challenge!</b> </em> <br> 
			[Paper] [Code] [Data]
		</td>
	</tr>


